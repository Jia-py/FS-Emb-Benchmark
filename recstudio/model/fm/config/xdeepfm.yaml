model:
  embed_dim: 16
  cin_layer_size: [200,200,200]
  mlp_layer: [64,64,64]
  activation: gelu
  dropout: 0.3
  direct: False

train:
  learning_rate: 0.0005
